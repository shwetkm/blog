{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://shwetkm.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "import numpy as np import pandas as pd import json from ipywidgets import interact from bokeh.plotting import figure, show, ColumnDataSource from bokeh.io import push_notebook, show, output_notebook from bokeh.plotting import figure output_notebook() . Loading BokehJS ... #your_local_path=&quot;F:/Study/Dashboard/Coffee/&quot; . with open(&#39;Cafe.json&#39;) as f: i=1 for line in f: coffee = pd.DataFrame(json.loads(line)) . # coffee = pd.read_json(&#39;Cafe1.json&#39;) #coffee = coffee.sample(n=1000) #coffee.reset_index(drop=True) . stdf = coffee[&#39;Monthly Data&#39;].apply(json.loads).apply(pd.Series) stdf.reset_index(drop=True) #stdf.head() . 2013:10 2013:11 2013:12 2013:9 2014:1 2014:10 2014:11 2014:12 2014:2 2014:3 ... 2016:8 2016:9 2017:1 2017:2 2017:3 2017:4 2017:5 2017:6 2017:7 2017:8 . 0 {&#39;NoOfEmployees&#39;: 12.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 13.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 14.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 11.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 15.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 31.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 32.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 34.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 16.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 17.0, &#39;CostIncurredAtStore&#39;:... | ... | {&#39;NoOfEmployees&#39;: 114.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 122.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 146.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 157.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 170.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 176.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 190.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 206.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 215.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 222.0, &#39;CostIncurredAtStore&#39;... | . 1 {&#39;NoOfEmployees&#39;: 12.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 13.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 14.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 11.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 15.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 30.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 31.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 34.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 17.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 18.0, &#39;CostIncurredAtStore&#39;:... | ... | {&#39;NoOfEmployees&#39;: 147.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 160.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 212.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 223.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 239.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 257.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 268.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 293.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 304.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 317.0, &#39;CostIncurredAtStore&#39;... | . 2 {&#39;NoOfEmployees&#39;: 12.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 13.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 14.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 11.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 15.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 28.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 30.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 32.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 16.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 17.0, &#39;CostIncurredAtStore&#39;:... | ... | {&#39;NoOfEmployees&#39;: 94.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 103.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 135.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 148.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 157.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 166.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 179.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 193.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 204.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 223.0, &#39;CostIncurredAtStore&#39;... | . 3 NaN | NaN | NaN | NaN | {&#39;NoOfEmployees&#39;: 11.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 24.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 26.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 27.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 12.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 13.0, &#39;CostIncurredAtStore&#39;:... | ... | {&#39;NoOfEmployees&#39;: 92.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 100.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 116.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 121.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 123.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 134.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 142.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 151.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 155.0, &#39;CostIncurredAtStore&#39;... | NaN | . 4 NaN | NaN | NaN | NaN | NaN | {&#39;NoOfEmployees&#39;: 18.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 19.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 21.0, &#39;CostIncurredAtStore&#39;:... | NaN | NaN | ... | {&#39;NoOfEmployees&#39;: 72.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 80.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 109.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 117.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 125.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 136.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 149.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 160.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 163.0, &#39;CostIncurredAtStore&#39;... | {&#39;NoOfEmployees&#39;: 174.0, &#39;CostIncurredAtStore&#39;... | . 5 NaN | NaN | NaN | NaN | NaN | NaN | {&#39;NoOfEmployees&#39;: 11.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 12.0, &#39;CostIncurredAtStore&#39;:... | NaN | NaN | ... | {&#39;NoOfEmployees&#39;: 49.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 53.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 62.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 67.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 74.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 77.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 83.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 90.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 97.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 99.0, &#39;CostIncurredAtStore&#39;:... | . 6 NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | {&#39;NoOfEmployees&#39;: 34.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 36.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 49.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 52.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 55.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 59.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 60.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 61.0, &#39;CostIncurredAtStore&#39;:... | {&#39;NoOfEmployees&#39;: 66.0, &#39;CostIncurredAtStore&#39;:... | NaN | . 7 rows × 48 columns . coffee = coffee[[&#39;Store ID&#39;, &#39;Name&#39;, &#39;Brand&#39;, &#39;Store Number&#39;, &#39;Phone Number&#39;, &#39;Ownership Type&#39;, &#39;Street Combined&#39;, &#39;Street 1&#39;, &#39;Street 2&#39;, &#39;Street 3&#39;, &#39;City&#39;, &#39;State&#39;, &#39;Country&#39;, &#39;Coordinates&#39;, &#39;Latitude&#39;, &#39;Longitude&#39;, &#39;Start Date&#39;, &#39;Monthly Data&#39;]] . #len(coffee.Country.unique()) . stdf.columns = range(0,len(stdf.columns)) . stdf[&#39;City&#39;] = coffee[&#39;City&#39;] stdf[&#39;Name&#39;] = coffee[&#39;Name&#39;] stdf_city = stdf[stdf[&#39;City&#39;] == &#39;Pune&#39;] #len(stdf_city[&#39;Name&#39;].unique()) . #stdf_city[0].apply(pd.Series) . Cost Incurred vs Revenue Plot for stores in Pune . *Bubble size represents Profits . from bokeh.palettes import Spectral11 from bokeh.models import HoverTool from bokeh.models import LinearInterpolator, CategoricalColorMapper from bokeh.models import ColumnDataSource sss = stdf_city[0].apply(pd.Series) Profit = sss[&#39;Profit&#39;] source = ColumnDataSource(dict( x= sss[&#39;CostIncurredAtStore&#39;], y= sss[&#39;RevenueOfStore&#39;], profit = sss[&#39;Profit&#39;], profit_scaled = Profit.apply(lambda x: abs(x/5)), stores = stdf_city[&#39;Name&#39;], emp = sss[&#39;NoOfEmployees&#39;], )) def update_m (month): sss = stdf_city[month].apply(pd.Series) Profit = sss[&#39;Profit&#39;] new_data = dict( x= sss[&#39;CostIncurredAtStore&#39;], y= sss[&#39;RevenueOfStore&#39;], stores = stdf_city[&#39;Name&#39;], emp = sss[&#39;NoOfEmployees&#39;], profit = Profit, profit_scaled = Profit.apply(lambda x: abs(x/5)) ) source.data = new_data #updating the source data with the newdata i.e data of each year p1.title.text = str(month) #updating the title push_notebook() #push this into chart size_mapper = LinearInterpolator( #this is to give size for each data point according to their population x=[5, 15], y = [3,5] ) #to give color to each type of data point color_mapper = CategoricalColorMapper( factors = list(stdf_city[&#39;Name&#39;].unique()), #this tells the compiler to color the continents palette = Spectral11,) hover = HoverTool(tooltips = [(&quot;Employee Count&quot;,&quot;@emp&quot;),(&quot;Profit&quot;,&quot;@profit&quot;), (&quot;Revenue&quot;,&quot;@y&quot;), (&quot;Cost Incurred&quot;,&quot;@x&quot;)], #when u hover mouse on data points show_arrow=False) PLOT_OPTS = dict( #the dimensions of figure is given height =450, width = 750, x_axis_type=&#39;log&#39;, x_range=[1300, 30000], y_range=(1500,30000) ) p1 = figure( #how do u want the overall dimensions of fig title = str(&#39;2013 October Cost Incurred vs Revenue&#39;),toolbar_location=&#39;above&#39;, #title should always be in string format title_location = &#39;above&#39;, tools=[hover], **PLOT_OPTS) p1.circle( x=&#39;x&#39;,y=&#39;y&#39;, #these have been wriiten before and is being called for the sake of hovering to work and is defined in update function size={&#39;field&#39;:&#39;profit_scaled&#39;}, #we cant use the size of data point as population as the china population is one billion and all the pixels gets filled and hence we use a mapper and give the rangee of X and y axis color = {&#39;field&#39;:&#39;stores&#39;,&#39;transform&#39;:color_mapper}, #this will color all the regions defined by color_mapper legend=&#39;stores&#39;, #a legend of which color is what continent source=source, #what is the data source alpha=0.9) #how much of transparency of data pojint p1.legend.border_line_color = None #to remove the border p1.legend.location = (10,0) #this is going to take legend out of the chart box p1.right.append(p1.legend[0]) #this is going to place the legend to the right show(p1, notebook_handle=True) #notebook_handle will take the consideration of viewing each year that we defined in update . /home/shwetakamal/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/api.py:107: RuntimeWarning: &#39;&lt;&#39; not supported between instances of &#39;str&#39; and &#39;int&#39;, sort order is undefined for incomparable objects result = result.union(other) /home/shwetakamal/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/api.py:107: RuntimeWarning: &#39;&lt;&#39; not supported between instances of &#39;int&#39; and &#39;str&#39;, sort order is undefined for incomparable objects result = result.union(other) . &lt;Bokeh Notebook handle for In[9]&gt; . interact(update_m, month=(0,47,1)) . &lt;function __main__.update_m(month)&gt; .",
            "url": "https://shwetkm.github.io/blog/2020/01/28/Interactive-Bubble-Plot.html",
            "relUrl": "/2020/01/28/Interactive-Bubble-Plot.html",
            "date": " • Jan 28, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://shwetkm.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Title",
            "content": "Pytorch Basics and Speed Comparisons with Numpy and GPU . Initialising, slicing, reshaping tensors | Numpy and PyTorch interfacing | GPU support for PyTorch + Enabling GPUs on Google Colab | Speed comparisons, Numpy -- PyTorch -- PyTorch on GPU | Autodiff concepts and application | Writing a basic learning loop using autograd | . import torch import numpy as np import matplotlib.pyplot as plt . Initialise tensors . x = torch.ones(3, 2) print(x) x = torch.zeros(3, 2) print(x) x = torch.rand(3, 2) print(x) . tensor([[1., 1.], [1., 1.], [1., 1.]]) tensor([[0., 0.], [0., 0.], [0., 0.]]) tensor([[0.2365, 0.3903], [0.9967, 0.0030], [0.5356, 0.1902]]) . x = torch.empty(3, 2) print(x) y = torch.zeros_like(x) print(y) . tensor([[5.1069e-36, 0.0000e+00], [0.0000e+00, 0.0000e+00], [0.0000e+00, 0.0000e+00]]) tensor([[0., 0.], [0., 0.], [0., 0.]]) . x = torch.linspace(0, 1, steps=5) print(x) . tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000]) . x = torch.tensor([[1, 2], [3, 4], [5, 6]]) print(x) . tensor([[1, 2], [3, 4], [5, 6]]) . Slicing tensors . print(x.size()) print(x[:, 1]) print(x[0, :]) . torch.Size([3, 2]) tensor([2, 4, 6]) tensor([1, 2]) . y = x[1, 1] print(y) print(y.item()) . tensor(4) 4 . Reshaping tensors . print(x) y = x.view(2, 3) print(y) . tensor([[1, 2], [3, 4], [5, 6]]) tensor([[1, 2, 3], [4, 5, 6]]) . y = x.view(6,-1) print(y) . tensor([[1], [2], [3], [4], [5], [6]]) . Simple Tensor Operations . x = torch.ones([3, 2]) y = torch.ones([3, 2]) z = x + y print(z) z = x - y print(z) z = x * y print(z) . tensor([[2., 2.], [2., 2.], [2., 2.]]) tensor([[0., 0.], [0., 0.], [0., 0.]]) tensor([[1., 1.], [1., 1.], [1., 1.]]) . z = y.add(x) print(z) print(y) . tensor([[2., 2.], [2., 2.], [2., 2.]]) tensor([[1., 1.], [1., 1.], [1., 1.]]) . z = y.add_(x) print(z) print(y) . tensor([[2., 2.], [2., 2.], [2., 2.]]) tensor([[2., 2.], [2., 2.], [2., 2.]]) . Numpy vs PyTorch . x_np = x.numpy() print(type(x), type(x_np)) print(x_np) . &lt;class &#39;torch.Tensor&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt; [[1. 1.] [1. 1.] [1. 1.]] . Convert Numpy array to Torch tensor . a = np.random.randn(5) print(a) a_pt = torch.from_numpy(a) print(type(a), type(a_pt)) print(a_pt) . [-0.22648217 2.33063636 -2.35281499 1.52592661 0.05184195] &lt;class &#39;numpy.ndarray&#39;&gt; &lt;class &#39;torch.Tensor&#39;&gt; tensor([-0.2265, 2.3306, -2.3528, 1.5259, 0.0518], dtype=torch.float64) . np.add(a, 1, out=a) print(a) print(a_pt) . [ 0.77351783 3.33063636 -1.35281499 2.52592661 1.05184195] tensor([ 0.7735, 3.3306, -1.3528, 2.5259, 1.0518], dtype=torch.float64) . Speed Comparison b/w Numpy and Torch on CPU . %%time for i in range(100): a = np.random.randn(100,100) b = np.random.randn(100,100) c = np.matmul(a, b) . CPU times: user 161 ms, sys: 117 ms, total: 278 ms Wall time: 158 ms . %%time for i in range(100): a = torch.randn([100, 100]) b = torch.randn([100, 100]) c = torch.matmul(a, b) . CPU times: user 32.2 ms, sys: 1.93 ms, total: 34.1 ms Wall time: 36.3 ms . %%time for i in range(10): a = np.random.randn(10000,10000) b = np.random.randn(10000,10000) c = a + b . CPU times: user 1min 36s, sys: 1.35 s, total: 1min 37s Wall time: 1min 37s . %%time for i in range(10): a = torch.randn([10000, 10000]) b = torch.randn([10000, 10000]) c = a + b . CPU times: user 16 s, sys: 9.8 ms, total: 16 s Wall time: 16 s . We can see that Pytorch on CPU is around 4-5 times faster than Numpy . CUDA support . print(torch.cuda.device_count()) . 1 . print(torch.cuda.device(0)) print(torch.cuda.get_device_name(0)) . &lt;torch.cuda.device object at 0x7f7ed42ee390&gt; Tesla K80 . We have Tesla K80 GPU running on this notebook. To know more about this GPU and its performance refer to this link. . cuda0 = torch.device(&#39;cuda:0&#39;) . a = torch.ones(3, 2, device=cuda0) b = torch.ones(3, 2, device=cuda0) c = a + b print(c) . tensor([[2., 2.], [2., 2.], [2., 2.]], device=&#39;cuda:0&#39;) . print(a) . tensor([[1., 1.], [1., 1.], [1., 1.]], device=&#39;cuda:0&#39;) . %%time for i in range(10): a = torch.randn([10000, 10000], device=cuda0) b = torch.randn([10000, 10000], device=cuda0) c = a + b . CPU times: user 3.19 ms, sys: 1.02 ms, total: 4.22 ms Wall time: 6.16 ms . We see drastic improvement in the performance on GPU. It is almost 800 times faster that pytorch on CPU and around 5000 times faster than Numpy. . Autodiff in Pytorch . Automatic differentiation (autodiff) refers to a general way of taking a program which computes a value, and automatically constructing a procedure for computing derivatives of that value. . x = torch.ones([3, 2], requires_grad=True) print(x) . tensor([[1., 1.], [1., 1.], [1., 1.]], requires_grad=True) . requires_grad=True is mandatory to tell Pytorch to do the book keeping of all the operations being performed with the data. . y = x + 5 print(y) . tensor([[6., 6.], [6., 6.], [6., 6.]], grad_fn=&lt;AddBackward0&gt;) . Here, grad_fn=&lt;AddBackward0&gt; is the way of book keeping in Pytorch . z = y*y + 1 print(z) . tensor([[37., 37.], [37., 37.], [37., 37.]], grad_fn=&lt;AddBackward0&gt;) . t = torch.sum(z) print(t) . tensor(222., grad_fn=&lt;SumBackward0&gt;) . t.backward() . print(x.grad) . tensor([[12., 12.], [12., 12.], [12., 12.]]) . $t = sum_i z_i, z_i = y_i^2 + 1, y_i = x_i + 5$ . $ frac{ partial t}{ partial x_i} = frac{ partial z_i}{ partial x_i} = frac{ partial z_i}{ partial y_i} frac{ partial y_i}{ partial x_i} = 2y_i times 1$ . At x = 1, y = 6, $ frac{ partial t}{ partial x_i} = 12$ . x = torch.ones([3, 2], requires_grad=True) y = x + 5 r = 1/(1 + torch.exp(-y)) print(r) s = torch.sum(r) s.backward() print(x.grad) . tensor([[0.9975, 0.9975], [0.9975, 0.9975], [0.9975, 0.9975]], grad_fn=&lt;MulBackward0&gt;) tensor([[0.0025, 0.0025], [0.0025, 0.0025], [0.0025, 0.0025]]) . x = torch.ones([3, 2], requires_grad=True) y = x + 5 r = 1/(1 + torch.exp(-y)) a = torch.ones([3, 2]) r.backward(a) print(x.grad) . tensor([[0.0025, 0.0025], [0.0025, 0.0025], [0.0025, 0.0025]]) . $ frac{ partial{s}}{ partial{x}} = frac{ partial{s}}{ partial{r}} cdot frac{ partial{r}}{ partial{x}}$ . For the above code $a$ represents $ frac{ partial{s}}{ partial{r}}$ and then $x.grad$ gives directly $ frac{ partial{s}}{ partial{x}}$ . Autodiff example that looks like what we usually do in Deep Learning . x = torch.randn([20, 1], requires_grad=True) y = 3*x - 2 . w = torch.tensor([1.], requires_grad=True) b = torch.tensor([1.], requires_grad=True) y_hat = w*x + b loss = torch.sum((y_hat - y)**2) . print(loss) . tensor(237.3524, grad_fn=&lt;SumBackward0&gt;) . loss.backward() . print(w.grad, b.grad) . tensor([-63.6629]) tensor([115.7930]) . Do it in a loop . learning_rate = 0.01 w = torch.tensor([1.], requires_grad=True) b = torch.tensor([1.], requires_grad=True) print(w.item(), b.item()) for i in range(10): x = torch.randn([20, 1]) y = 3*x - 2 y_hat = w*x + b loss = torch.sum((y_hat - y)**2) loss.backward() with torch.no_grad(): w -= learning_rate * w.grad b -= learning_rate * b.grad w.grad.zero_() b.grad.zero_() print(w.item(), b.item()) . 1.0 1.0 2.2244343757629395 -0.46036696434020996 2.5868167877197266 -1.0856199264526367 2.58056902885437 -1.3719744682312012 2.7070467472076416 -1.6221551895141602 2.808570146560669 -1.7485421895980835 2.8510940074920654 -1.842361330986023 2.863948106765747 -1.877304196357727 2.9146628379821777 -1.9155502319335938 2.9505720138549805 -1.9522515535354614 2.9600718021392822 -1.9627878665924072 . We can see that w is approaching towards 3 and b towards -2. . Do it for a large problem . %%time learning_rate = 0.001 N = 10000000 epochs = 200 w = torch.rand([N], requires_grad=True) b = torch.ones([1], requires_grad=True) # print(torch.mean(w).item(), b.item()) for i in range(epochs): x = torch.randn([N]) y = torch.dot(3*torch.ones([N]), x) - 2 y_hat = torch.dot(w, x) + b loss = torch.sum((y_hat - y)**2) loss.backward() with torch.no_grad(): w -= learning_rate * w.grad b -= learning_rate * b.grad w.grad.zero_() b.grad.zero_() # print(torch.mean(w).item(), b.item()) . CPU times: user 32.2 s, sys: 86.4 ms, total: 32.2 s Wall time: 32.3 s . %%time learning_rate = 0.001 N = 10000000 epochs = 200 w = torch.rand([N], requires_grad=True, device=cuda0) b = torch.ones([1], requires_grad=True, device=cuda0) # print(torch.mean(w).item(), b.item()) for i in range(epochs): x = torch.randn([N], device=cuda0) y = torch.dot(3*torch.ones([N], device=cuda0), x) - 2 y_hat = torch.dot(w, x) + b loss = torch.sum((y_hat - y)**2) loss.backward() with torch.no_grad(): w -= learning_rate * w.grad b -= learning_rate * b.grad w.grad.zero_() b.grad.zero_() #print(torch.mean(w).item(), b.item()) . CPU times: user 837 ms, sys: 492 ms, total: 1.33 s Wall time: 1.34 s . At last again some speed comparison b/w Pytorch on CPU vs GPU. On CPU it took 32.3 secs and on GPU, only 1.34 secs. . References: I learnt these basics of Pytorch from https://www.guvi.in/ .",
            "url": "https://shwetkm.github.io/blog/2020/01/04/Pytorch-Basics-and-Speed-Comparisons-with-Numpy-and-GPU.html",
            "relUrl": "/2020/01/04/Pytorch-Basics-and-Speed-Comparisons-with-Numpy-and-GPU.html",
            "date": " • Jan 4, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://shwetkm.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}